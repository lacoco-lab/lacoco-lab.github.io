# Milestones in Machine Learning and Language: Historical Readings

## Course Description

Modern AI feels like it’s everywhere — models that write, speak, see, play games, and even arguably reason. However many researchers today feel a sense of déjà vu: incremental papers, rebranded benchmarks, recycled ideas. Are we reaching the limits of what can be achieved just by scaling models? Is the field running out of new ideas?

This seminar takes a step back — and way back — to understand how machine learning and language technology evolved: both technically as well as philosophically. We’ll examine the early hopes, dead ends, breakthroughs, and rediscoveries that brought us to today's transformer-based models

We'll ask:
- What did early AI researchers believe language and learning were?
- Why were neural networks once declared useless — and then revived to define modern AI?
- What kinds of research actually shifted paradigms?
- Are we at a similar inflection point today?

**Prerequisites:**
This seminar will not presuppose knowledge of any of these fields. However, a willingness to engage with technical content is important.


We'll read classic work from figures like **Turing, Shannon, Chomsky, Rosenblatt, Minsky, Angluin, Valiant, Hinton, Bengio, LeCun, and Pearl**. Reading these old papers might *feel* like a waste of time in a field obsessed with the latest preprint — but our hope is that the takeaways will prove useful, maybe even generative. By studying where ideas came from (and how they were nearly lost), you may come away with **a deeper appreciation of today’s models — and new ways to think about the next generation of models.**


**Course Management System:** [CMS](https://cms.sic.saarland/theory_2526/) TBD

**Instructors:** Yash Sarrof and Michael Hahn

**Time:** TBD

**Room:** TBD

**Registration:**
* If you are an **LST / CoLi** student, and want to take this class, you should directly register in the [Course Management System (CMS)](https://cms.sic.saarland/theory_2526/). TBD Admissions decision will be made around the end of the first week of the semester.

* If you are a **Computer Science** student, you should initially register via the Computer Science department seminar registration system. If you want to take the seminar but were not selected by the assignment system, please apply for the waiting list by emailing xhuang@lst.uni-saarland.de. Only register in [Course Management System (CMS)](https://cms.sic.saarland/theory_2526/) TBD once you were selected by the assignment system or otherwise admitted by us.


## Syllabus
---

## Weekly Syllabus

Each week covers foundational work in AI, ML, or NLP, presented by students and followed by discussion. Pairings are based on thematic coherence. 
Welcome to change the list.

### **some background**
Might teach for 2-3 weeks, concepts that will be used across the papers. 


### **Week 1 – Computation and Intelligence**
- Turing (1936): *On Computable Numbers*
- Turing (1950): *Computing Machinery and Intelligence*

### **Week 2 – Information and Early AI**
- Shannon (1948): *A Mathematical Theory of Communication*
- Arthur Samuel (1959): *Some Studies in Machine Learning Using the Game of Checkers*

### **Week 3 – Language: Structure vs. Distribution**
- Zellig Harris (1954): *Distributional Structure*
- Noam Chomsky (1956): *Three Models for the Description of Language*

### **Week 4 – The Perceptron and the First AI Winter**
- Rosenblatt (1958): *The Perceptron*
- Minsky & Papert (1969): *Perceptrons*

### **Week 5 – Symbolic Reasoning and Natural Language**
- Minsky (1961): *Steps Toward Artificial Intelligence*
- Winograd (1972): *Understanding Natural Language (SHRDLU)*

### **Week 6 – Formal Models of Learnability**
- Gold (1967): *Language Identification in the Limit*
- Angluin (1980): *Inductive Inference of Formal Languages from Positive Data*

### **Week 7 – Learning and Generalization: Theory Meets Computation**
- Solomonoff (1964): *A Formal Theory of Inductive Inference*
- Valiant (1984): *A Theory of the Learnable*

### **Week 8 – Birth of Deep Learning**
- Rumelhart, Hinton, Williams (1986): *Learning Representations by Back-Propagating Errors*
- LeCun et al. (1989): *Backpropagation Applied to Handwritten Zip Code Recognition*
- Bengio et al. (2007): *Greedy Layer-Wise Training of Deep Networks*

### **Week 9**
- Some papers from 2000's maybe in complexity class / ci
- some other papers we can think of, need to think more about this. 

---

## Evaluation

### 4 CP version:
- **Presentation**: 60%  
- **Weekly reading questions**: 40%

### 7 CP version:
- **Presentation**: 30%  
- **Reading questions**: 20%  
- **Final paper/project**: 50%

---

## Weekly Reading Questions

- Submit **one question per week** (by Tuesday at noon).
- Grading:
  - 0 = not submitted  
  - 1 = superficial  
  - 2 = thoughtful / insightful
- You're welcome to submit more than one — the highest score will count.

---

## Presentations

- Students present in **pairs**.
- Provide:
  - Historical context
  - Motivation and key contributions
  - Technical novelty at the time
  - Critical analysis
  - Connections to other papers
- Encourage and moderate **discussion throughout**.
- Target: **45 min presentation + 30–40 min discussion**

---
## Evaluation

***Important: Study programs may differ in which versions of the class you can take. Please check with your study program coordinator if in doubt.***

For students taking the seminar for 4 credits:

    Presentation: 60%
    Questions about readings: 40%

For students taking the seminar for 7 credits:

    Presentation: 30%
    Questions about readings: 20%
    Final paper: 50%

### Questions

Please register on the forum on CMS.

Starting from the fourth week, every student submits one question about the readings by Tuesday noon.
Questions are graded on a 3-point scale (0: no question submitted, 1: superficial question, 2: insightful question). Students can also submit a few more questions, the grade will be calculated as the highest score among questions.（So you can also ask some basic questions that you want clarification.

### Presentations

We expect that presentations will cover the key points from the readings, such as the main evidence for and against the key claims under consideration in the paper.

We do not expect that presentations will cover all details of the papers. Rather, you should focus on big picture findings and conclusions, and are not expected to include every finding from the paper in your presentation.
For instance, instead of a table of numbers, highlight key results.
When there are multiple similar results in the paper, synthesize them.
If the papers have many studies, you might select a presentative subset to explain the paper's conclusions.
On the other hand, if the assigned papers primarily discuss/review other work, draw on material from the work cited to provide richer content and even details where useful. Also, sometimes there is just one paper in a seminar session, so you will have more time and may cover more details.

Make sure to motivate the papers' research question(s).
Give background on key concepts, and convey to the audience your understanding of why certain research decisions were made.

Select what you consider the key points; you are not expected to cover every part of the paper exhaustively. Include details only to the extent that you believe them to be important.

Critically engage with the reading: contribute your own opinion on the key findings, and on the paper's motivation and arguments. In what ways do or don't you agree with arguments made by the authors?

As you'll be presenting in teams of two, don't just present the two papers separately, but make sure to also draw connections and compare.
Aim for 40-60 minutes of presentation, allowing 30-40 minutes of discussion. You will have sufficient time, so avoid speaking too fast for others to keep up, make sure your audience is following. You can do so by giving more examples, or simply repeating again. Making presentation is to convey information, if audience cannot follow, it's waste of time for both sides.
Generating and moderating in-class discussion is a key component of your presentation -- thinking about what will be interesting to your audience will thus be important.
Discussion should happen not just after the presentation, but you should engage the audience and create ample opportunity for discussion during your presentation.
Before the presentation, take a look at the questions that have been posted in the forum and refer to these as needed. These may be useful for getting discussion started.
Conversely, when attending other students' talks, reciprocate by participating actively in the discussion.


### Final Papers (for the 7CP version)

**Note: We will discuss this in the first meeting. Requirements may be changed based on popular demand.**

Term papers will be about a small independent project.

You will investigate some question about the abilities of language models.
The report is expected to contain a brief literature review, motivation of your study, a description of what you did, and you found. It's recommended to include quantitative validation of what you found, so that you show it's not an illusion.

The report should have 8 pages of main report, plus unlimited appendix, in the NeurIPS style format. The main report should be self-contained, but you can use the appendix to report prompts, further analyses, or other material.

The report should be uploaded via CMS. The due date is October TBD, 2025, 23:59.

Everyone is expected to report on their project idea in the TBD, session, and to participate in discussion to give feedback to other students' ideas. Feel free to come up with any ideas that might be interesting. Students may prepare a short slide deck on their idea. This will not be graded; the session is intended to help improve and finetune project ideas.

## Contact

Please contact Yash (ysarrof@lst.uni-saarland.de) or Michael (mhahn@lst.uni-saarland.de) for any questions.

## Accommodations

If you need any accommodations due to a disability or chronic illness, please either contact Michael at mhahn@lst.uni-saarland.de or the [Equal Opportunities and Diversity Management Unit](https://www.uni-saarland.de/en/administration/diversity.html) of the university.

