# Language Models as Cognitive Models

**Course Description:** Today's large language models can show behavior that looks strikingly intelligent. This raises many questions about their relation to, and differences from, human cognition and intelligence. This seminar course dives into this rapidly emerging field at the intersection of NLP, language, and cognition.

Students should have a basic understanding of natural language processing.


**Course Management System:** [CMS](https://cms.sic.saarland/langmod_cogmod_ws23/)

**Instructors:** [Kate McCurdy](https://kmccurdy.github.io/), [Michael Hahn](https://www.mhahn.info/)

**Time:** Tue 16:15â€“17:45

**Room:** Building C7.3, Seminarraum 1.12


## Format and requirements

This is a seminar course.
Starting from the fourth week, one or two students will present in each unit (except for the Dec 12 session). Every student will present exactly once.
We expect all students to read the readings every week. Every student submits one question about the readings by Monday evening.


## Syllabus

**Note: The syllabus is subject to change. We will discuss this in the first and second meeting.**
  
| Date          | Topic               | Readings  | Slides  | Optional Material | Presenter  |
| ------------- | ------------------- | ------- | ------- | --------------------- | ---------- |
| 2023-10-24    | First Meeting               |  |  |                | [Michael](https://www.mhahn.info/)   | 
| 2023-10-31    | Introduction to (L)LMs               |   | TBD  |                 | [Michael](https://www.mhahn.info/)  | 
| 2023-11-07    | no class               |  |  |                |          | 
| 2023-11-14  ---  2023-12-12 | Unit 1: LMs as cognitive models of language ||||| <!--| 2023-11-14 | Past tense debate: Historical overview | [Seidenberg & Plaut 2014](http://doi.wiley.com/10.1111/cogs.12147) |  | [Rumelhart & McClelland 1986](http://stanford.edu/~jlmcc/papers/PDP/Chapter18.pdf), [Pinker & Prince 1988](http://linkinghub.elsevier.com/retrieve/pii/0010027788900327) |  |-->
| 2023-11-14 | Past tense debate  | [Kirov & Cotterell 2018, TACL](https://aclanthology.org/Q18-1045/), [Corkery et al. 2019, ACL](https://www.aclweb.org/anthology/P19-1376) |  |   [Seidenberg & Plaut 2014](http://doi.wiley.com/10.1111/cogs.12147), [Rumelhart & McClelland 1986](http://stanford.edu/~jlmcc/papers/PDP/Chapter18.pdf), [Pinker & Prince 1988](http://linkinghub.elsevier.com/retrieve/pii/0010027788900327), [McCurdy et al 2020, ACL](https://arxiv.org/abs/2005.08826)  | TBD |
| 2023-11-21 | Symbolic computation and composition  | [Lake and Baroni 2018, ICML](http://proceedings.mlr.press/v80/lake18a.html), [Santoro and Lampinen et al. 2022](http://arxiv.org/abs/2102.03406) |    |                  | TBD         | 
| 2023-11-28 | Surprisal and next-word prediction |   [Wilcox et al 2020, CogSci](https://cognitivesciencesociety.org/cogsci20/papers/0375/0375.pdf),   [Oh and Schuler 2023, TACL](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00548/115371/Why-Does-Surprisal-From-Larger-Transformer-Based) |   |  [Hale 2001, NAACL](https://dl.acm.org/doi/10.3115/1073336.1073357), [Levy 2008, Cognition](https://pages.ucsd.edu/~rlevy/papers/levy-2008-cognition.pdf) | TBD | 
| 2023-12-05 |  LLM's capabilities in formal vs functional language use | [Mahowald and Ivanova et al., 2023, arXiv](http://arxiv.org/abs/2301.06627) |   |  | TBD | 
| 2023-12-12 | Discussing project ideas | | | | everyone |
| 2024-01-02  ---  2024-02-06 | Unit 2: LMs as cognitive models of understanding |  |  |  |  |
| 2024-01-02   | How do we know how smart AI systems are? The debate over LLM understanding | [Mitchell 2023, Science](https://www.science.org/doi/10.1126/science.adj5957); [Mitchell and Krakauer 2023, PNAS](https://www.pnas.org/doi/abs/10.1073/pnas.2215907120)  |    |                  | TBD         | 
| 2024-01-09   | Using cognitive psychology to understand GPT-3              | [Binz and Schulz 2023, PNAS](https://www.pnas.org/doi/10.1073/pnas.2218523120), [Binz and Schulz 2023, arxiv](https://arxiv.org/abs/2306.03917)   |    |                | TBD         | 
| 2024-01-16   | Theory of Mind in LLMs             | [Kosinski 2022, arXiv](http://arxiv.org/abs/2302.02083), [Ullman 2023, arXiv](http://arxiv.org/abs/2302.08399)  |    |                  | TBD         | 
| 2024-01-23   | Debate over Reference in LLMs     | [Bender and Koller 2020, ACL](https://aclanthology.org/2020.acl-main.463),  [Pavlick 2023](https://royalsocietypublishing.org/doi/10.1098/rsta.2022.0041)  |    |     [Piantadosi and Hill 2022, arXiv](http://arxiv.org/abs/2208.02957), [Patel and Pavlick 2023, ICLR](https://openreview.net/forum?id=gJcEM8sxHK)             | TBD         | 
| 2024-01-30   | Comparison to children's cognitive development  | [Frank 2023, PsyArXiv](https://psyarxiv.com/uacjm/), [Yiu et al. 2023, arXiv](http://arxiv.org/abs/2305.07666)  |    |                  | TBD         | 
| 2024-02-06   | How next-word prediction mediates LLM reasoning  | [McCoy et al. 2023, arXiv](https://arxiv.org/pdf/2309.13638.pdf)  |    |                  | TBD         | 


## Evaluation


For students taking the seminar for 4 credits:

    Presentation: 60%
    Questions about readings: 40%

For students taking the seminar for 7 credits:

    Presentation: 40%
    Questions about readings: 20%
    Final paper: 40%

### Questions

Starting from the fourth week (Nov 13), every student submits one question about the readings by Monday evening.
Questions are graded on a 3-point scale (0: no question submitted, 1: superficial question, 2: insightful question).

### Presentations

We expect that presentations will cover the key points from the readings, such as the main evidence for and against the key claims under consideration in the paper.

We do not expect that presentations will cover all details of the papers. Rather, you should focus on big picture findings and conclusions, and are not expected to include every finding from the paper in your presentation.
For instance, instead of a table of numbers, highlight key result.
When there are multiple similar results in the paper, synthesize them.
If the papers have many studies, you might select a representative subset to explain the paper's conclusions.

Make sure to motivate the papers' research question(s).
Give background on key concepts, and convey to the audience your understanding of why certain research decisions were made.

Select what you consider the key points; you are not expected to cover every part of the paper exhaustively. Include details only to the extent that you believe them to be important.

If you present two papers, do not just present them separately. Rather, draw connections, and compare and contrast where appropriate.

Critically engage with the reading: contribute your own opinion on the key findings, and on the paper's motivation and arguments. In what ways do or don't you agree with arguments made by the authors?


<!--- Key information covered in sufficient detail
  - ex.: main evidence for / against research question & claim

- Thematic presentation - big picture findings are clear
  - ex.: instead of a table of numbers, highlight key result
  - ex. motivating the research question
  - ex. giving background on key concepts, why certain research decisions were made

- Critical engagement - student should contribute their own opinion on the key findings-->


### Term Papers

**Note: We will discuss this in the first and second meeting. Requirements may be changed based on popular demand.**

Term papers will be about a small independent project.
You will investigate a question about LLMs' cognitive ability via prompting. For instance, you might test their ability to perform a certain kind of reasoning, or investigate how they respond to certain kinds of stimuli.

Option 1: You may develop your own question and prompts. In this case, you will be expected to design at least 25 (not more than 50) prompts.

Option 2: You may draw on a larger existing benchmark. In this case, you will be expected to find some new angle on the benchmark, e.g., by tweaking the stimuli or by evaluating the LLM's behavior in a different way.

The report is expected to contain a brief literature review, motivation of your question, a description of your prompts, and evaluation of the LLM's behavior. The report is expected to include quantitative evaluation of the LLM's behavior (e.g., using measures such as accuracy). Additionally including qualitative evaluation can also be beneficial.

<!--independent project: proposal on cognitive question to investigate through LLM prompting + small lit review 
  develop own question / stimuli - smaller number of data for evaluation required, e.g. 25-50 
  larger / exisiting benchmark, we expect some statistical evaluation. maybe tweak / build on-->

The report should have 8 pages of main report, plus unlimited appendix. The main report should be self-contained, but you can use the appendix to report prompts, further analyses, or other material.

The report should be uploaded via CMS. The due date is April 8, 2024, 23:59.

Everyone is expected to report on their project idea in the December 12, 2023, session, and to participate in discussion to give feedback to other students' ideas. Students may prepare a short slide deck on their idea. This will not be graded; the December 12 session is intended to help improve and finetune project ideas.

## Office hours

Please contact Kate (kmccurdy@lst.uni-saarland.de) or Michael (mhahn@lst.uni-saarland.de) to schedule a meeting.

## Accommodations


<!--TODO copied from Sebastian-->

If you need any accommodations due to a disability or chronic illness, please either contact Michael at mhahn@lst.uni-saarland.de or the [Equal Opportunities and Diversity Management Unit](https://www.uni-saarland.de/en/administration/diversity.html) of the university.

<!--# All students are welcome

TODO copied from Sebastian

We are committed to doing what we can to work for equity and to create an inclusive learning environment that actively values the diversity of backgrounds, identities, and experiences of everyone in this seminar. We also know that we will sometimes make missteps. If you notice some way that we could do better, we hope that you will let us know about it.-->
